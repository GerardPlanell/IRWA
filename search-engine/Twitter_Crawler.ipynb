{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "Twitter_Crawler_Definitive.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxVLstKx3O49"
      },
      "source": [
        "# Final Project IRWA: Twitter Crawling\r\n",
        "\r\n",
        "This section of the code was made in other subject project by Gerard, and adapted to cover the requisites of the data in this project. But it was so prepared to convert the json to csv that was a nonsense not using to old jason from Gerard project and make slight changes to keep only the needed columns in the csv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zUvbZPL3O5D"
      },
      "source": [
        "## 1. Install and import needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xu4cuTA3O5F"
      },
      "source": [
        "import tweepy\n",
        "import simplejson as json\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import Stream\n",
        "from tweepy.streaming import StreamListener\n",
        "\n",
        "import time\n",
        "import re"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22hpggzt3O5F"
      },
      "source": [
        "## 2.  Gathering tweets in real-time related to US 2020 Elections\n",
        "\n",
        "\n",
        "Here is the code used to crawl the tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYQ0f2Yl3O5F"
      },
      "source": [
        "#Twitter Developer keys and tokens\n",
        "'''\n",
        "consumer_key=\n",
        "consumer_secret=\n",
        "access_token=\n",
        "access_secret=\n",
        " \n",
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_secret) '''"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "Pq0Op0T63O5G",
        "outputId": "bc93d860-ca31-46d0-e6c3-1605a18b0141"
      },
      "source": [
        "# Crawl tweets and store them in 'E:\\Tweets\\Output_v3.json' and a sample of the dataset in 'E:\\Tweets\\Output_sample.json'\n",
        "tweetsPerQry = 100000\n",
        "maxTweets = 3000000\n",
        "import json\n",
        "\n",
        "hashtag = ['Trump OR Biden OR Democrat OR Republican OR Kamala OR Pence OR #Trump OR #Biden OR #Democrat OR #Republican OR #Kamala OR #Pence']\n",
        "api = tweepy.API(auth)\n",
        "places = api.geo_search(query=\"USA\", granularity=\"country\")\n",
        "place_id = places[0].id\n",
        "place = \" -filter:retweets AND place:\"+str(place_id)\n",
        "\n",
        "hashtag = hashtag[0] + place\n",
        "print(hashtag)\n",
        "maxId = -1\n",
        "tweetCount = 0\n",
        "authentication = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "authentication.set_access_token(access_token, access_secret)\n",
        "\n",
        "while tweetCount < maxTweets:\n",
        "\n",
        "\n",
        "\n",
        "    api = tweepy.API(authentication, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
        "    if(maxId <= 0):\n",
        "        newTweets = api.search(q=hashtag, count=tweetsPerQry, result_type=\"recent\", tweet_mode=\"extended\")\n",
        "        \n",
        "    else:\n",
        "        newTweets = api.search(q=hashtag, count=tweetsPerQry, max_id=str(maxId - 1), result_type=\"recent\", tweet_mode=\"extended\")\n",
        "    \n",
        "    if not newTweets:\n",
        "        print(\"Tweet Habis\")\n",
        "        break\n",
        "\n",
        "    try:\n",
        "        name='Output_v3.json'\n",
        "        with open(name, 'a') as f:\n",
        "            for tweet in newTweets:\n",
        "                json.dump(tweet._json, f) # This will store the whole JSON data in the file, you can perform some JSON filters\n",
        "        if(tweetCount==0):\n",
        "            name='Output_sample.json'\n",
        "            with open(name, 'a') as f:\n",
        "                for tweet in newTweets:\n",
        "                    json.dump(tweet._json+'\\n', f)    \n",
        "\n",
        "            # Setting a limit in the number of tweets collected\n",
        "            \n",
        "    except BaseException as e:\n",
        "        print(\"Error on_data: %s\" % str(e))\n",
        "\n",
        "    tweetCount += len(newTweets)\n",
        "    print(tweetCount/maxTweets*100)\n",
        "    maxId = newTweets[-1].id\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trump OR Biden OR Democrat OR Republican OR Kamala OR Pence OR #Trump OR #Biden OR #Democrat OR #Republican OR #Kamala OR #Pence -filter:retweets AND place:96683cc9126741d1\n",
            "Error on_data: unsupported operand type(s) for +: 'dict' and 'str'\n",
            "0.0033333333333333335\n",
            "0.006666666666666667\n",
            "0.01\n",
            "0.013333333333333334\n",
            "0.016666666666666666\n",
            "0.02\n",
            "0.023333333333333334\n",
            "0.02666666666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a895993b1271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mnewTweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhashtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtweetsPerQry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxId\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"recent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"extended\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnewTweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;31m# Set pagination mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                                                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                                                 \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                                                 proxies=self.api.proxy)\n\u001b[0m\u001b[1;32m    191\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTweepError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Failed to send request: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mca_cert_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca_cert_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             ssl_context=context)\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_fingerprint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir)\u001b[0m\n\u001b[1;32m    343\u001b[0m             or IS_SECURETRANSPORT):\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mserver_hostname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         warnings.warn(\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    405\u001b[0m                          \u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                          \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                          _context=self, _session=session)\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     def wrap_bio(self, incoming, outgoing, server_side=False,\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context, _session)\u001b[0m\n\u001b[1;32m    815\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1075\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1077\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1078\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;34m\"\"\"Start the SSL/TLS handshake.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zklG5aN96ygj"
      },
      "source": [
        "(The error is beacause we only tried to run for a few iterations and we interrupted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eW_tzpJ3O5H"
      },
      "source": [
        "# 3. Extracting the data\r\n",
        "\r\n",
        "We extract the needed parts of the jsons and transform it into managable file system in csv format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeLnl5st3O5H"
      },
      "source": [
        "### Store the JSON data in a CSV for analysing\n",
        "#### Panel of control\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw1P_-Sm3O5I"
      },
      "source": [
        "class control:\n",
        "    def  __init__(self,location):\n",
        "        with open(location, 'r', encoding='utf-8') as dat:\n",
        "            self.data = json.load(dat, encoding='utf-8')\n",
        "            self.location = location\n",
        "    def update(self,num):\n",
        "        self.data[\"seed\"]=str(num)\n",
        "    def tweet_count(self):\n",
        "        return(int(self.data[\"seed\"]))\n",
        "    def window(self):\n",
        "        return(int(self.data[\"window\"]))\n",
        "    def start(self):\n",
        "        return(int(self.data[\"start\"]))\n",
        "    def end(self):\n",
        "        return(int(self.data[\"end\"]))\n",
        "    def save(self):\n",
        "        with open(self.location, 'w') as dat:\n",
        "            json.dump(self.data,dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSYPUiX73O5I"
      },
      "source": [
        "# The file where we saved our tweets\n",
        "json_file = 'E:\\Tweets\\Output_v3.json'\n",
        "json_file_corrected = 'E:\\Tweets\\Output_v5.json'\n",
        "\n",
        "# Properties stored in prop.json\n",
        "properties_data= 'prop.json'\n",
        "\n",
        "# The file where we are going to save:\n",
        "# tweet_count,id,created_at,retweet_count,favorite_count,lang,user.id_str,user.screen_name,user.followers_count,\n",
        "# user.friend_count,user.listed_count,user.created_at,place.full_name,place.country\n",
        "csv_file_data = 'Output_v5_data.csv'\n",
        "\n",
        "# This file will store: tweet_count,user.screen_name,entities.user_mentions.screen_name\n",
        "csv_file_ment = 'Output_v5_ment.csv'\n",
        "\n",
        "# This file will store: tweet_count,user.screen_name,entities.hastags\n",
        "csv_file_hash = 'Output_v5_hash.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12ktqoWm3O5I"
      },
      "source": [
        "#Code extracted from https://stackoverflow.com/questions/3173320/text-progress-bar-in-the-console/3173338\n",
        "#We used beacause helps to visualize\n",
        "# Prints a progress bar\n",
        "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
        "    \"\"\"\n",
        "    Call in a loop to create terminal progress bar\n",
        "    @params:\n",
        "        iteration   - Required  : current iteration (Int)\n",
        "        total       - Required  : total iterations (Int)\n",
        "        prefix      - Optional  : prefix string (Str)\n",
        "        suffix      - Optional  : suffix string (Str)\n",
        "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
        "        length      - Optional  : character length of bar (Int)\n",
        "        fill        - Optional  : bar fill character (Str)\n",
        "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
        "    \"\"\"\n",
        "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
        "    filledLength = int(length * iteration // total)\n",
        "    bar = fill * filledLength + '-' * (length - filledLength)\n",
        "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
        "    # Print New Line on Complete\n",
        "    if iteration == total: \n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QTAzQdU3O5J"
      },
      "source": [
        "# Functions to read the different files and initialize csv\n",
        "def read_tweet_data(tweet_count,tweet):\n",
        "    field_list = ['created_at','favorite_count','retweet_count']\n",
        "    \n",
        "    csv_data_string=str(tweet_count)+','\n",
        "    \n",
        "    ###\n",
        "    text=str(tweet['full_text'])\n",
        "    text=clean(text)\n",
        "    csv_data_string+=('\\\"'+text+'\\\",')\n",
        "    csv_data_string+=clean(str(tweet['user']['screen_name']))+','\n",
        "    ##\n",
        "    for field in field_list:\n",
        "        csv_data_string+=clean(str(tweet[field]))+','\n",
        "    csv_data_string+='https://twitter.com/twitter/statuses/'+clean(str(tweet['id']))+'\\n'\n",
        "    \n",
        "    return (csv_data_string)\n",
        "\n",
        "        \n",
        "def read_ment_data(tweet_count,tweet):\n",
        "    if (len(tweet['entities']['user_mentions'])>0):\n",
        "        csv_ment_string=''\n",
        "        for mention in tweet['entities']['user_mentions']:\n",
        "            csv_ment_string+=(str(tweet_count)+','+str(tweet['user']['screen_name'])+','\n",
        "                             +str(mention['screen_name'])+'\\n')\n",
        "        return(csv_ment_string)\n",
        "    return('')\n",
        "\n",
        "def read_hash_data(tweet_count,tweet):\n",
        "    if (len(tweet['entities']['hashtags'])>0):\n",
        "        csv_hash_string=''\n",
        "        for hashtag in tweet['entities']['hashtags']:\n",
        "            csv_hash_string+=(str(tweet_count)+','+str(tweet['user']['screen_name'])+','\n",
        "                             +str(hashtag['text'])+'\\n')\n",
        "        return(csv_hash_string)\n",
        "    return('')\n",
        "        \n",
        "def initialize_csv():\n",
        "    tweet_data='tweet_count,text,user_screen_name,created_at,favorite_count,retweet_count,url\\n'   \n",
        "    tweet_ment='tweet_count,user_mentioner,user_mentionated\\n'\n",
        "    tweet_hash='tweet_count,user_screen_name,hastags\\n'\n",
        "    return(tweet_data,tweet_ment,tweet_hash)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSDM0rmQ3O5J"
      },
      "source": [
        "# Functions to read and write blocks of tweets (with all the information needed) to the corresponding files\n",
        "def read_next_block(f_jsonfile,window,pointer):\n",
        "    block=[]\n",
        "    block.append(f_jsonfile.readline())\n",
        "    if(block[0]!=''): \n",
        "        for i in range(window-1):\n",
        "            block.append(f_jsonfile.readline())\n",
        "        pointer.append(block)\n",
        "\n",
        "def write_data(tweet_data,tweet_ment,tweet_hash):\n",
        "    f_data=open(csv_file_data, 'a+',encoding=\"utf-8\",errors='ignore')\n",
        "    f_data.write(tweet_data)\n",
        "    f_data.close()\n",
        "    f_ment=open(csv_file_ment, 'a+',encoding=\"utf-8\",errors='ignore')\n",
        "    f_ment.write(tweet_ment)\n",
        "    f_ment.close()\n",
        "    f_hash=open(csv_file_hash, 'a+',encoding=\"utf-8\",errors='ignore')\n",
        "    f_hash.write(tweet_hash)\n",
        "    f_hash.close()\n",
        "\n",
        "    \n",
        "def read_block(data,block,dump):\n",
        "    tweet_count = data.tweet_count()\n",
        "    \n",
        "    if tweet_count==0:\n",
        "        tweet_data,tweet_ment,tweet_hash=initialize_csv()\n",
        "    else:\n",
        "        tweet_data=''\n",
        "        tweet_ment=''\n",
        "        tweet_hash=''\n",
        "    for tweet in block:\n",
        "        try:\n",
        "            tweet=json.loads(tweet)\n",
        "            if ((tweet_count<data.end())&(tweet['lang']=='en')):\n",
        "                \n",
        "                tweet_data_temp=read_tweet_data(tweet_count,tweet)\n",
        "\n",
        "                tweet_ment_temp=read_ment_data(tweet_count,tweet)\n",
        "                tweet_hash_temp=read_hash_data(tweet_count,tweet)\n",
        "\n",
        "                #if doesnt break append\n",
        "                tweet_data+=tweet_data_temp\n",
        "                tweet_ment+=tweet_ment_temp\n",
        "                tweet_hash+=tweet_hash_temp\n",
        "                tweet_count+=1\n",
        "        except Exception as e:\n",
        "            \n",
        "            dump[0]+=1\n",
        "            #dump[1]+=(str(tweet)+'\\n')    \n",
        "            \n",
        "    write_data(tweet_data,tweet_ment,tweet_hash)\n",
        "    data.update(tweet_count)\n",
        "\n",
        "def clean(string):\n",
        "    string=re.sub(r'\\\"','', string)\n",
        "    string=re.sub(r',','', string)\n",
        "    string=re.sub(r'\\n','', string)\n",
        "    return(string)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "sJguwl343O5K",
        "outputId": "9eb4a4be-629c-4156-f54d-b98b3b00b5d2"
      },
      "source": [
        "#from threading import Thread\n",
        "#BREAK#This is to avoid accidental runs that may affect your data\n",
        "import time\n",
        "\n",
        "start_time=time.time()\n",
        "data = control(properties_data)\n",
        "with open(json_file_corrected, 'r') as f_jsonfile:\n",
        "    old= data.tweet_count()\n",
        "    dump=[0,'']\n",
        "    while(data.tweet_count()<data.end()):\n",
        "        old= data.tweet_count()\n",
        "        block=[]\n",
        "        dump[1]=[]\n",
        "        read_next_block(f_jsonfile,data.window(),block)\n",
        "        read_block(data,block[0],dump)\n",
        "        if len(block)==0:break\n",
        "\n",
        "        dtime=time.time()-start_time\n",
        "        printProgressBar((data.start()+data.tweet_count()),data.end(),length=75,\n",
        "                             suffix = 'Complete, time: '+str(dtime)+ ', estimation {}'.format(((data.end()-data.start())/(data.start()+data.tweet_count())*dtime/60)))\n",
        "        data.save()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " |███████████████████████████████████████████████████████████████████████████| 100.0% Complete, time: 203.94645762443542, estimation 3.3991076270739238\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}